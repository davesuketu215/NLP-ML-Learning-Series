{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3aa3ce9-a0f4-4f08-84a6-57360e328f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682ba7c5-e7ca-4e23-b332-f38f731b77b8",
   "metadata": {},
   "source": [
    "# Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c06b1514-9387-4c46-8745-d8010206f9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>abstract</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Accessible Visual Artworks for Blind and Visua...</td>\n",
       "      <td>Quero, Luis Cavazos; Bartolome, Jorge Iranzo; ...</td>\n",
       "      <td>Despite the use of tactile graphics and audio ...</td>\n",
       "      <td>accessibility technology; multimodal interacti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Seizure Detection and Prediction by Parallel M...</td>\n",
       "      <td>Li, Chenqi; Lammie, Corey; Dong, Xuening; Amir...</td>\n",
       "      <td>During the past two decades, epileptic seizure...</td>\n",
       "      <td>CNN; Seizure Detection; Seizure Prediction; EE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Fast ScanNet: Fast and Dense Analysis of Multi...</td>\n",
       "      <td>Lin, Huangjing; Chen, Hao; Graham, Simon; Dou,...</td>\n",
       "      <td>Lymph node metastasis is one of the most impor...</td>\n",
       "      <td>Histopathology image analysis; computational p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Long-Term Effectiveness of Antiretroviral Ther...</td>\n",
       "      <td>Huang, Peng; Tan, Jingguang; Ma, Wenzhe; Zheng...</td>\n",
       "      <td>In order to assess the effectiveness of the Ch...</td>\n",
       "      <td>HIV; ART; mortality; observational cohort stud...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Real-Time Facial Affective Computing on Mobile...</td>\n",
       "      <td>Guo, Yuanyuan; Xia, Yifan; Wang, Jing; Yu, Hui...</td>\n",
       "      <td>Convolutional Neural Networks (CNNs) have beco...</td>\n",
       "      <td>facial affective computing; convolutional neur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uuid                                              title  \\\n",
       "0     0  Accessible Visual Artworks for Blind and Visua...   \n",
       "1     1  Seizure Detection and Prediction by Parallel M...   \n",
       "2     2  Fast ScanNet: Fast and Dense Analysis of Multi...   \n",
       "3     3  Long-Term Effectiveness of Antiretroviral Ther...   \n",
       "4     4  Real-Time Facial Affective Computing on Mobile...   \n",
       "\n",
       "                                              author  \\\n",
       "0  Quero, Luis Cavazos; Bartolome, Jorge Iranzo; ...   \n",
       "1  Li, Chenqi; Lammie, Corey; Dong, Xuening; Amir...   \n",
       "2  Lin, Huangjing; Chen, Hao; Graham, Simon; Dou,...   \n",
       "3  Huang, Peng; Tan, Jingguang; Ma, Wenzhe; Zheng...   \n",
       "4  Guo, Yuanyuan; Xia, Yifan; Wang, Jing; Yu, Hui...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Despite the use of tactile graphics and audio ...   \n",
       "1  During the past two decades, epileptic seizure...   \n",
       "2  Lymph node metastasis is one of the most impor...   \n",
       "3  In order to assess the effectiveness of the Ch...   \n",
       "4  Convolutional Neural Networks (CNNs) have beco...   \n",
       "\n",
       "                                            Keywords  label  \n",
       "0  accessibility technology; multimodal interacti...      0  \n",
       "1  CNN; Seizure Detection; Seizure Prediction; EE...      1  \n",
       "2  Histopathology image analysis; computational p...      1  \n",
       "3  HIV; ART; mortality; observational cohort stud...      0  \n",
       "4  facial affective computing; convolutional neur...      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"./data/input/train.csv\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef9d7310-bb3a-4ba7-a473-8588e0c13ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 2)\n"
     ]
    }
   ],
   "source": [
    "data_df.drop(columns=['uuid', 'title', 'author', 'Keywords'], inplace=True, axis=1)\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9337af05-db0f-499c-94a8-fffa3d86274c",
   "metadata": {},
   "source": [
    "# Data Cleaning & Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92194a58-57b2-4e89-a38b-e93784744f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5f0898c-7b9f-4555-bf3e-689cd402611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2677a16-f79c-4041-bfb7-bd3ae3d8af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "870e699f-d650-4abe-aefc-1023f26eb5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>label</th>\n",
       "      <th>custom_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Despite the use of tactile graphics and audio ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[despite, use, tactile, graphic, audio, guide,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>During the past two decades, epileptic seizure...</td>\n",
       "      <td>1</td>\n",
       "      <td>[past, two, decade, epileptic, seizure, detect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lymph node metastasis is one of the most impor...</td>\n",
       "      <td>1</td>\n",
       "      <td>[lymph, node, metastasis, one, important, indi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In order to assess the effectiveness of the Ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>[order, ass, effectiveness, chinese, governmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Convolutional Neural Networks (CNNs) have beco...</td>\n",
       "      <td>0</td>\n",
       "      <td>[convolutional, neural, networks, cnns, become...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Previously we showed the generation of a prote...</td>\n",
       "      <td>1</td>\n",
       "      <td>[previously, show, generation, protein, trap, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Facial emotion recognition (FER) is a field of...</td>\n",
       "      <td>0</td>\n",
       "      <td>[facial, emotion, recognition, fer, field, res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This paper proposes a machine learning model b...</td>\n",
       "      <td>0</td>\n",
       "      <td>[paper, proposes, machine, learn, model, base,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Most current state-of-the-art blind image qual...</td>\n",
       "      <td>0</td>\n",
       "      <td>[current, state, art, blind, image, quality, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Surgical workflow recognition has numerous pot...</td>\n",
       "      <td>1</td>\n",
       "      <td>[surgical, workflow, recognition, numerous, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Due to the lack of available episomal plasmid,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[due, lack, available, episomal, plasmid, impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>In contrast to numerous studies on spermatozoa...</td>\n",
       "      <td>1</td>\n",
       "      <td>[contrast, numerous, study, spermatozoon, leng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Study on finger knuckle patterns has attracted...</td>\n",
       "      <td>0</td>\n",
       "      <td>[study, finger, knuckle, pattern, attract, inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>In the present work, we follow in chronologica...</td>\n",
       "      <td>0</td>\n",
       "      <td>[present, work, follow, chronological, order, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Curved text detection is a difficult problem t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[curved, text, detection, difficult, problem, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Refugees are a vulnerable, growing population ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[refugees, vulnerable, grow, population, confr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Weakly supervised object detection (WSOD) usin...</td>\n",
       "      <td>0</td>\n",
       "      <td>[weakly, supervise, object, detection, wsod, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>This paper presents a novel, fast, group-wise ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[paper, present, novel, fast, group, wise, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Limited by the electrostatic interaction, the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[limited, electrostatic, interaction, oxidatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The integration of analytical strategies and g...</td>\n",
       "      <td>0</td>\n",
       "      <td>[integration, analytical, strategy, global, op...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             abstract  label  \\\n",
       "0   Despite the use of tactile graphics and audio ...      0   \n",
       "1   During the past two decades, epileptic seizure...      1   \n",
       "2   Lymph node metastasis is one of the most impor...      1   \n",
       "3   In order to assess the effectiveness of the Ch...      0   \n",
       "4   Convolutional Neural Networks (CNNs) have beco...      0   \n",
       "5   Previously we showed the generation of a prote...      1   \n",
       "6   Facial emotion recognition (FER) is a field of...      0   \n",
       "7   This paper proposes a machine learning model b...      0   \n",
       "8   Most current state-of-the-art blind image qual...      0   \n",
       "9   Surgical workflow recognition has numerous pot...      1   \n",
       "10  Due to the lack of available episomal plasmid,...      1   \n",
       "11  In contrast to numerous studies on spermatozoa...      1   \n",
       "12  Study on finger knuckle patterns has attracted...      0   \n",
       "13  In the present work, we follow in chronologica...      0   \n",
       "14  Curved text detection is a difficult problem t...      0   \n",
       "15  Refugees are a vulnerable, growing population ...      1   \n",
       "16  Weakly supervised object detection (WSOD) usin...      0   \n",
       "17  This paper presents a novel, fast, group-wise ...      1   \n",
       "18  Limited by the electrostatic interaction, the ...      1   \n",
       "19  The integration of analytical strategies and g...      0   \n",
       "\n",
       "                                     custom_tokenized  \n",
       "0   [despite, use, tactile, graphic, audio, guide,...  \n",
       "1   [past, two, decade, epileptic, seizure, detect...  \n",
       "2   [lymph, node, metastasis, one, important, indi...  \n",
       "3   [order, ass, effectiveness, chinese, governmen...  \n",
       "4   [convolutional, neural, networks, cnns, become...  \n",
       "5   [previously, show, generation, protein, trap, ...  \n",
       "6   [facial, emotion, recognition, fer, field, res...  \n",
       "7   [paper, proposes, machine, learn, model, base,...  \n",
       "8   [current, state, art, blind, image, quality, a...  \n",
       "9   [surgical, workflow, recognition, numerous, po...  \n",
       "10  [due, lack, available, episomal, plasmid, impr...  \n",
       "11  [contrast, numerous, study, spermatozoon, leng...  \n",
       "12  [study, finger, knuckle, pattern, attract, inc...  \n",
       "13  [present, work, follow, chronological, order, ...  \n",
       "14  [curved, text, detection, difficult, problem, ...  \n",
       "15  [refugees, vulnerable, grow, population, confr...  \n",
       "16  [weakly, supervise, object, detection, wsod, u...  \n",
       "17  [paper, present, novel, fast, group, wise, reg...  \n",
       "18  [limited, electrostatic, interaction, oxidatio...  \n",
       "19  [integration, analytical, strategy, global, op...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "do_remove_punct = True\n",
    "do_lemmatize = True\n",
    "do_lowercase = True\n",
    "do_remove_stop = True\n",
    "do_remove_nums = True\n",
    "\n",
    "def custom_tokenize(row):\n",
    "    text = row['abstract']\n",
    "    \n",
    "    # 01 - Punctuations\n",
    "    if do_remove_punct:\n",
    "        text = re.sub(r'([^\\w\\s])', ' ', text)\n",
    "\n",
    "    # 02 - Lemmatization\n",
    "    if do_lemmatize:\n",
    "        tokens_list = nltk.word_tokenize(text)\n",
    "        text = ' '.join([lemmatizer.lemmatize(t, get_wordnet_pos(t)) for t in tokens_list])\n",
    "\n",
    "    # 03 - Lowercasing\n",
    "    if do_lowercase:\n",
    "        text = text.lower()\n",
    "\n",
    "    # 04 - Removing stop words (i.e. grammar defining words, not adding value to main topic)\n",
    "    if do_remove_stop:\n",
    "        text = ' '.join([t for t in text.split() if t not in stopwords])\n",
    "\n",
    "    # 05 - Removing numbers\n",
    "    if do_remove_nums:\n",
    "        text = re.sub(r'\\b[0-9]+\\b', ' ', text)\n",
    "\n",
    "    # Removing redundant spaces\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "\n",
    "    row['custom_tokenized'] = text.split()\n",
    "    return row\n",
    "\n",
    "data_df['custom_tokenized'] = [list() for _ in range(data_df.shape[0])]\n",
    "data_df = data_df.apply(custom_tokenize, axis=1)\n",
    "\n",
    "data_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a0ffec-57e7-425b-b000-abdc3d4ed2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbb35909-61f9-441e-a5b1-4905d410d98e",
   "metadata": {},
   "source": [
    "# Data Split - Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "040ed118-c9f1-456c-8b1f-4210b9dcfc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data_df[['abstract', 'custom_tokenized']]\n",
    "Y = data_df[['label']]\n",
    "\n",
    "X_train_text, X_val_text, Y_train, Y_val = train_test_split(X, \n",
    "                                                            Y, \n",
    "                                                            test_size=0.2, \n",
    "                                                            shuffle=True, \n",
    "                                                            random_state=42\n",
    "                                                           )\n",
    "del X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1397cda-8414-4b9a-929f-8168f6a4ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_docs_train = X_train_text['custom_tokenized'].tolist()\n",
    "corpus_docs_val = X_val_text['custom_tokenized'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8213290-596d-4248-8902-53d18f851c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_docs_train_1 = [' '.join([token for token in tokenized_doc]) for tokenized_doc in corpus_docs_train]\n",
    "corpus_docs_val_1 = [' '.join([token for token in tokenized_doc]) for tokenized_doc in corpus_docs_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15ecf9a3-56d0-4d09-908b-6cfe2bfdbba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image partition important preprocessing step many state art algorithm use perform high level computer vision task typically partition conduct without regard task hand propose task specific image partition framework produce region base image representation lead high task performance reach use task oblivious partition framework exist supervise partition framework albeit number propose method partition image mean correlation cluster maximize linear discriminant function define superpixel graph parameter discriminant function define task specific similarity dissimilarity among superpixels estimate base structure support vector machine svm use task specific training data svm learn lead well generalization ability construction superpixel graph use define discriminant function allows rich set feature incorporate improve discriminability robustness evaluate learn task aware partition algorithm three benchmark datasets results show task aware partition lead well label performance partition compute state art general purpose supervise partition algorithm believe task specific image partition paradigm widely applicable improve performance high level image understand task'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_docs_train_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "651d1bac-e92c-4619-acd2-502fbac8dcc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'colonoscopy tool choice prevent colorectal cancer detect remove polyp become cancerous however colonoscopy hamper fact endoscopists routinely miss polyp miss polyp appear endoscopist field view others miss simply substandard coverage procedure e colon see paper attempt rectify problem substandard coverage colonoscopy introduction c2d2 colonoscopy coverage deficiency via depth algorithm detects deficient coverage thereby alert endoscopist revisit give area specifically c2d2 consists two separate algorithm first performs depth estimation colon give ordinary rgb video stream second computes coverage give depth estimate rather compute coverage entire colon algorithm computes coverage locally segment segment basis c2d2 indicate real time whether particular area colon suffer deficient coverage endoscopist return area coverage algorithm first algorithm evaluate large scale way depth estimation technique first calibration free unsupervised method apply colonoscopy c2d2 algorithm achieves state art result detection deficient coverage synthetic sequence ground truth time accurate human expert real sequence c2d2 achieves agreement expert'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_docs_val_1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e01cda-8f19-423c-9f6c-320d376bebf9",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f2b463-db06-453b-ad7d-266c9d447b61",
   "metadata": {},
   "source": [
    "#### Instantiating vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83a024ec-0c7b-481a-a512-3fbe6c775ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', \n",
    "                                   ngram_range=(1,1),\n",
    "                                   min_df=20,          # Features should occur in minimum this much number of documents\n",
    "                                   max_df=0.8          # Features should occur in at the max this much proportion of documents\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65404895-d88d-4907-956c-8e6b22da08e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.8, min_df=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>TfidfVectorizer(max_df=0.8, min_df=20)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_df=0.8, min_df=20)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c39f7d8-a753-4248-adf4-09342f053ef8",
   "metadata": {},
   "source": [
    "#### Fitting the vectorizer on Train data\n",
    "#### And transforming the Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd02e8f9-956b-4220-b789-c0da887a9170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e075951a-7345-4ac5-9862-eb4ee385f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_train = tfidf_vectorizer.fit_transform(corpus_docs_train_1)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9c0a58-cce6-4b30-8964-8e17727afbb2",
   "metadata": {},
   "source": [
    "#### Transforming the Validation data\n",
    "#### Never fit on Validation or Test data! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a78824df-d0e7-498d-a653-0f3573d768eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_val = tfidf_vectorizer.transform(corpus_docs_val_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736194bb-82c4-4680-9f97-fabd0662e60c",
   "metadata": {},
   "source": [
    "### How does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "684da4a3-872a-4dcd-be15-136ac7b8a9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4800x2881 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 328360 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5677aaa-4c3b-4e15-a647-15a2986c9d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2881 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 82 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40179049-ed0e-443e-8821-49ef873483e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9b625fd-ca7d-4f01-84ea-d99566a43e4d",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b58501-2bf6-473c-9e17-4551a4dc450d",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46425c1a-9b37-43d1-bbad-4a73e6990715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(tfidf_matrix_train, Y_train)\n",
    "Y_pred = logreg.predict(tfidf_matrix_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8cc6a18-8948-4793-8252-74a5c03a49f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy 0.9575\n",
      "Validation F1 score: 0.9575014462297675\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print('Validation accuracy %s' % accuracy_score(Y_val, Y_pred))\n",
    "print('Validation F1 score: {}'.format(f1_score(Y_val, Y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1d41b0-cef4-4159-994a-bf2a2783b60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95c9fd29-f9b5-4e14-8b57-8f13ee231b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(Y_val, Y_pred, labels=logreg.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=logreg.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5c1a28-cb64-499f-8bd9-7a5357002742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "082a44ef-93a0-443a-969c-a0c3d7a378fa",
   "metadata": {},
   "source": [
    "### Cross Validation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c48fda37-5d5c-4612-a81f-b41ddc8b43d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Coagulate train and test data to one single data\n",
    "# Infact this should not be needed if the above training process was not done :)\n",
    "X = vstack([tfidf_matrix_train, tfidf_matrix_val])\n",
    "y = Y_train['label'].tolist() + Y_val['label'].tolist()\n",
    "\n",
    "cv_results = cross_validate(logreg, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83b2516f-fdc0-459f-bebd-24f06f9f222f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.04799771, 0.04639435, 0.06246328, 0.05562401, 0.15072489]),\n",
       " 'score_time': array([0., 0., 0., 0., 0.]),\n",
       " 'test_score': array([0.9525    , 0.96083333, 0.95416667, 0.95666667, 0.95916667])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fce9bc2-2e54-41af-9ec6-51f18276b889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
